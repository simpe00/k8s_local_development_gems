# Copyright Broadcom, Inc. All Rights Reserved.
# SPDX-License-Identifier: APACHE-2.0

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  # TODO: define shared azure imageRegistry
  imageRegistry: ""

extraDeploy: []
## @param initScripts Dictionary of init scripts. Evaluated as a template.
## Specify dictionary of scripts to be run at first boot
## Alternatively, you can put your scripts under the files/docker-entrypoint-initdb.d directory
## For example:
## initScripts:
##   my_init_script.sh: |
##      #!/bin/sh
##      echo "Do something."
##
initScripts: {}
## @param initScriptsCM ConfigMap with the init scripts. Evaluated as a template.
## Note: This will override initScripts
##
initScriptsCM: ""
## @param initScriptsSecret Secret containing `/docker-entrypoint-initdb.d` scripts to be executed at initialization time that contain sensitive data. Evaluated as a template.
##
initScriptsSecret: ""

## @section Spark parameters
##

# TODO: define shared azure imageRegistry
## Bitnami Spark image version
## ref: https://hub.docker.com/r/bitnami/spark/tags/
## @param image.registry [default: REGISTRY_NAME] Spark image registry
## @param image.repository [default: REPOSITORY_NAME/spark] Spark image repository
## @skip image.tag Spark image tag (immutable tags are recommended)
## @param image.digest Spark image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
## @param image.pullPolicy Spark image pull policy
## @param image.pullSecrets Specify docker-registry secret names as an array
## @param image.debug Enable image debug mode
##
image:
  registry: docker.io
  repository: bitnami/spark
  tag: 3.5.1-debian-12-r6

## @section Spark master parameters
##

## Spark master specific configuration
##
master:
  automountServiceAccountToken: true
  ## @param master.containerPorts.http Specify the port where the web interface will listen on the master over HTTP
  ## @param master.containerPorts.https Specify the port where the web interface will listen on the master over HTTPS
  ## @param master.containerPorts.cluster Specify the port where the master listens to communicate with workers
  ##
  containerPorts:
    http: 8080
    https: 8480
    cluster: 7077
  ## @param master.hostAliases Deployment pod host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param master.extraContainerPorts Specify the port where the running jobs inside the masters listens
  ## ref: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#containerport-v1-core
  ## e.g:
  ## - name: myapp
  ##   containerPort: 8000
  ##   protocol: TCP
  ##
  extraContainerPorts: []
  ## @param master.daemonMemoryLimit Set the memory limit for the master daemon
  ##
  daemonMemoryLimit: ""
  ## @param master.configOptions Use a string to set the config options for in the form "-Dx=y"
  ##
  configOptions: ""
  ## @param master.extraEnvVars Extra environment variables to pass to the master container
  ## For example:
  ## extraEnvVars:
  ##  - name: SPARK_DAEMON_JAVA_OPTS
  ##    value: -Dx=y
  ##
  extraEnvVars: []
  ## @param master.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for master nodes
  ##
  extraEnvVarsCM: ""
  ## @param master.extraEnvVarsSecret Name of existing Secret containing extra env vars for master nodes
  ##
  extraEnvVarsSecret: ""
  command: []
  ## @param master.args Override default container args (useful when using custom images)
  ##
  args: []

  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000

## @section Spark worker parameters
##
## Spark worker specific configuration
##
worker:
  automountServiceAccountToken: true
  replicaCount: 1
  # TODO: enable autoscaling
  autoscaling:
    enabled: true
#    minReplicas: 1
    maxReplicas: 5
    targetCPU: 50
    targetMemory: ""

  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
## @section Security parameters
##

## Security configuration
##
security:
  ## @param security.passwordsSecretName Name of the secret that contains all the passwords
  ## This is optional, by default random passwords are generated
  ##
  passwordsSecretName: ""
  ## @param security.certificatesSecretName Name of the secret that contains the certificates.
  ## It should contains two keys called "spark-keystore.jks" and "spark-truststore.jks" with the files in JKS format.
  ## DEPRECATED. Use `security.ssl.existingSecret` instead
  ##
  certificatesSecretName: ""

# TODO: ingress
ingress:
  ## @param ingress.enabled Enable ingress controller resource
  ##
  enabled: true
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.apiVersion Force Ingress API version (automatically detected if not set)
  ##
  apiVersion: ""
  ## @param ingress.hostname Default host for the ingress resource
  ##
  hostname: spark.local
  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: ""
  ## @param ingress.path The Path to Spark. You may need to set this to '/*' in order to use this with ALB ingress controllers.
  ##
  path: /
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/annotations.md
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ##
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {}
  ## @param ingress.tls Enable TLS configuration for the hostname defined at ingress.hostname parameter
  ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.ingress.hostname }}
  ## You can use the ingress.secrets parameter to create this TLS secret or rely on cert-manager to create it
  ##
  tls: false
  ## @param ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
  ##
  selfSigned: false
  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record.
  ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
  ## extraHosts:
  ## - name: spark.local
  ##   path: /
  ##
  extraHosts: []
  ## @param ingress.extraPaths Any additional arbitrary paths that may need to be added to the ingress under the main host.
  ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
  ## extraPaths:
  ## - path: /*
  ##   backend:
  ##     serviceName: ssl-redirect
  ##     servicePort: use-annotation
  ##
  extraPaths: []
  ## @param ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.
  ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  ## extraTls:
  ## - hosts:
  ##     - spark.local
  ##   secretName: spark.local-tls
  ##
  extraTls: []
  ## @param ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets
  ## key and certificate should start with -----BEGIN CERTIFICATE----- or
  ## -----BEGIN RSA PRIVATE KEY-----
  ##
  ## name should line up with a tlsSecret set further up
  ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
  ##
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  ## e.g:
  ## - name: spark.local-tls
  ##   key:
  ##   certificate:
  ##
  secrets: []
  ## @param ingress.extraRules Additional rules to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
  ## e.g:
  ## extraRules:
  ## - host: spark.local
  ##     http:
  ##       path: /
  ##       backend:
  ##         service:
  ##           name: spark-svc
  ##           port:
  ##             name: http
  ##
  extraRules: []
## @section Other parameters
##

## @section Metrics parameters
##
## Metrics configuration
##
metrics:
  ## @param metrics.enabled Start a side-car prometheus exporter
  ##
  enabled: true
  ## @param metrics.masterAnnotations [object] Annotations for the Prometheus metrics on master nodes
  ##
  masterAnnotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/metrics/'
    prometheus.io/port: '{{ .Values.master.containerPorts.http }}'
  ## @param metrics.workerAnnotations [object] Annotations for the Prometheus metrics on worker nodes
  ##
  workerAnnotations:
    prometheus.io/scrape: 'true'
    prometheus.io/path: '/metrics/'
    prometheus.io/port: '{{ .Values.worker.containerPorts.http }}'